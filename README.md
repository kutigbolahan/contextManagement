# ğŸ§  Simple Python Chatbot with Memory, Context & JSON Conversation Storage

This project is a lightweight chatbot built in Python using the **OpenAI API** (or **Ollama** locally).  
It supports:

âœ… Conversation memory  
âœ… Long-term JSON conversation saving  
âœ… Automatic summarization to reduce token usage  
âœ… Load & continue past chats  
âœ… Switch between OpenAI and local LLaMA via Ollama  
âœ… Command-based terminal interaction  

---

## âœ¨ Features

### **1. Memory + Context**
The chatbot stores each user and assistant message inside a `messages` list, allowing it to maintain conversation flow naturally.

### **2. JSON Conversation Saving**
Conversations can be saved and loaded anytime using simple commands:
```
save     â†’ saves to conversation.json  
load     â†’ loads previous conversation  
summary  â†’ summarizes old messages  
quit     â†’ exit program
```

### **3. Supports Both OpenAI & Ollama**
You choose the engine at runtime:

- **GPT-4o-mini** (OpenAI cloud)
- **LLaMA 3.2** (local via Ollama)

### **4. Automatic Token Optimization**
When messages become long, the system auto-summarizes the conversation to save tokens while preserving context.

---

## ğŸš€ How It Works

### **Initialization**
The chatbot creates initial system instructions:
```python
def create_initial_messages():
    return [{"role": "system", "content": "You are a helpful assistant."}]
```

### **Real-time Conversation**
Your input is appended and sent to the model:
```python
response = client.chat.completions.create(model=model_name, messages=messages)
```

### **Saving Conversations**
```python
with open("conversation.json", "w") as f:
    json.dump(messages, f)
```

### **Loading Conversations**
```python
return json.load(f)
```

### **Summarizing Conversation**
The last few messages are compressed into a shorter summary to reduce token usage.

---

## ğŸ–¥ï¸ Running the Chatbot

1. Install dependencies:
```
pip install openai python-dotenv
```

2. Add your OpenAI key to `.env`:
```
OPENAI_API_KEY=your_key_here
```

3. Run the script:
```
python main.py
```

4. Choose model:
```
1 â†’ OpenAI GPT-4o-mini  
2 â†’ Local LLaMA via Ollama
```

5. Start chatting!

---

## ğŸ“ File: `conversation.json`
This file stores your past chats so the assistant can remember them later.

Example:
```json
[
  {"role": "user", "content": "Hello!"},
  {"role": "assistant", "content": "Hi, how can I help you today?"}
]
```

---

## ğŸ“Œ Commands You Can Use
Inside the chatbot:

| Command | Action |
|---------|---------|
| `save` | Save conversation to JSON |
| `load` | Load conversation from JSON |
| `summary` | Summarize long conversation |
| `quit` | Exit program |

---

## ğŸ§© Code Overview
The project includes:

- **initialize_client()** â€“ chooses OpenAI or Ollama  
- **chat()** â€“ main conversation logic  
- **summarize_messages()** â€“ memory compression  
- **save_conversation()** â€“ saves chat  
- **load_conversation()** â€“ loads chat  
- **main()** â€“ command-line interface  

---

## ğŸ“œ License
Open source â€” feel free to modify or extend.

---

## â­ Future Improvements
- Embedding-based long-term memory  
- Vector database (Chroma/FAISS)  
- UI version using Gradio or Streamlit  
- Voice input support  
- Agent-style tool usage

---


